---
title: "Exploration, Tidy data and Linear, lasso + ridge"
author: "Mirco Bazzani"
date: "11/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(ggcorrplot)
library(caret)
library(fastDummies)
library(kableExtra)

training <- read_csv("Data/training.csv")

```


## Initial exploration

What we want to achieve is to gain an approximate regression on housing prices using descriptiv metrics of individual flats such as room numbers, floors and additional metrics based on location.

The dataset we are goint to use consists of 100 variables and 90'000 rows.


```{r summary full dataset, include=FALSE}
summary(training)

```


The dataset is way to extensive. We wil therefore kick out all Variables with a large amount of missing values.


```{r}

training %>% mutate_at(c("KTKZ", "GDENR", "floors", "quarter_general",""), as.factor) %>% 
  mutate_at(c("balcony","cabletv","elevator","kids_friendly",
              "parking_indoor","parking_outside"), as.logical) %>%
  mutate(year_built = as.numeric(year_built)) %>% 
  replace_na(list(balcony = FALSE, 
                  cabletv = FALSE,
                  elevator= FALSE,
                  kids_friendly= FALSE,
                  parking_indoor= FALSE,
                  parking_outside= FALSE)) %>% 
  mutate(date = as.Date(date, format ="%d.%m.%Y")) -> training

training %>% select(rent_full,
                    GDENR, #If we want to match our dataset with external data
                    KTKZ, #Could be interesting, as flat prices vary per canton
                    area, 
                    home_type,
                    balcony, #Small amount of missing values
                    cabletv, #Small amount of missing values
                    elevator,
                    floors,
                    msregion, #Not clear what this means
                    parking_indoor,
                    parking_outside,
                    quarter_general,
                    rooms,
                    year_built,
                    Micro_rating,
                    Micro_rating_NoiseAndEmission,
                    Micro_rating_Accessibility,
                    Micro_rating_DistrictAndArea,
                    Micro_rating_SunAndView,
                    Micro_rating_ServicesAndNature,
                    wgh_avg_sonnenklasse_per_egid,
                    Anteil_auslaend,
                    Avg_age,
                    Avg_size_household,
                    Noise_max,
                    anteil_efh,
                    apoth_pix_count_km2,
                    avg_anzhl_geschosse,
                    dist_to_4G,
                    dist_to_haltst,
                    dist_to_highway,
                    dist_to_lake,
                    dist_to_main_stat,
                    dist_to_school_1,
                    dist_to_train_stat,
                    geb_wohnnutz_total,
                    dist_to_river,
                    restaur_pix_count_km2, 
                    superm_pix_count_km2) -> training_reduced_large

training %>% select(rent_full, #If we want to match our dataset with external data
                    GDENR, #If we want to match our dataset with external data
                    KTKZ, #Could be interesting, as flat prices vary per canton
                    area, 
                    balcony, #Small amount of missing values
                    cabletv, #Small amount of missing values
                    elevator,
                    floors,
                    msregion, #Not clear what this means
                    parking_indoor,
                    parking_outside,
                    quarter_general,
                    rooms,
                    year_built,
                    Micro_rating,
                    Micro_rating_NoiseAndEmission,
                    Micro_rating_Accessibility,
                    Micro_rating_DistrictAndArea,
                    Micro_rating_SunAndView,
                    Micro_rating_ServicesAndNature
                    ) -> training_microrating

training %>% select(rent_full,
                    GDENR, #If we want to match our dataset with external data
                    KTKZ, #Could be interesting, as flat prices vary per canton
                    area, 
                    balcony, #Small amount of missing values
                    cabletv, #Small amount of missing values
                    elevator,
                    floors,
                    msregion, #Not clear what this means
                    parking_indoor,
                    parking_outside,
                    quarter_general,
                    rooms,
                    year_built,
                    Anteil_auslaend,
                    Avg_age,
                    Avg_size_household,
                    Noise_max,
                    anteil_efh,
                    apoth_pix_count_km2,
                    avg_anzhl_geschosse,
                    dist_to_4G,
                    dist_to_haltst,
                    dist_to_highway,
                    dist_to_lake,
                    dist_to_main_stat,
                    dist_to_school_1,
                    dist_to_train_stat,
                    geb_wohnnutz_total,
                    dist_to_river,
                    restaur_pix_count_km2, 
                    superm_pix_count_km2) -> training_no_microrating

```


This left us with 3 datasets.

* One includes both micro ratings and descriptive variables about the surrounding area. k = 39 variables.
* One only contains the micro ratings and data about the flat. k = 20 variables.
* One without the micro ratings in order to surpass possible covariance.


```{r}

training_reduced_large %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram()

training_reduced_large %>% select(dist_to_haltst) %>% 
  mutate(dist_to_haltst = log(dist_to_haltst)) %>% 
  ggplot(aes(dist_to_haltst)) +
  geom_histogram() +
  labs(title = "Log-transformation of distance to the next bus stop")

training_reduced_large %>% 
  keep(is.factor) -> factors
  
factors %>% ggplot(aes(KTKZ)) +
  geom_bar() + 
  labs(title = "Count per canton") -> p1

factors %>% ggplot(aes(floors)) +
  geom_bar() +
  labs(title = "Count per floor") -> p2

factors %>% ggplot(aes(quarter_general)) +
  geom_bar() +
  labs(title = "Count of quarter Index")  -> p3

grid.arrange(p1,p2,p3, nrow = 2)
```

The **micro-ratings** follow an approximate normal distribution, and are therefore ok. We could use them as regressors without any hassle.

But most of the numeric values are right skewed, this includes:
area
"Avg_size_household", 
"dist_to_haltst",
"dist_to_highway",
"dist_to_lake",
"dist_to_main_stat",
"dist_to_river",
"dist_to_school_1",
"dist_to_train_stat"

A log-transformation could come in handy on order to improve the regression model.

Note: The dependent variable is skewed as well, but if we log this one too the interpretability of our model decreases, so I'm not sure if it would be a good idea.

Furthermore: the log-regression makes sense for the linear model, but I do not know if we should do that for the other aproaches as well.




### Linear Model

```{r No logged values}
training_no_microrating %>% select(!GDENR) -> tr_mr

lm_norm <- lm_log <- lm(data = tr_mr, rent_full ~ .)
lm_norm
summary(lm_norm)
plot(lm_norm)
```

If none of the values are logged, we get an $R^2$ of .703. This is already pretty good.

What happens if we log the rent:

```{r R Dependent is logged}

lm_log_dep <- lm_log <- lm(data = tr_mr, log(rent_full) ~ .)
summary(lm_log_dep)
plot(lm_log_dep)

```
This leaves us with an increase of $R^2$ by 3%

As a last experiment I want to log both the dependent and the independent values:

```{r Linear Log Model - both sides logged}
summary(training_no_mr_log)
training_no_mr_log %>% select(!GDENR) -> tr_no_mr_log
lm_log <- lm(data = tr_no_mr_log, log(rent_full) ~ .)
summary(lm_log)
plot(lm_log)
data.frame(summary(lm_log)$coef[summary(lm_log)$coef[,4] <= .05, 4])

```

This increases the model accuracy even further. Lets try predictions with both of the logged models.

What we can say for all of the 3 fitted models is that they are really bad at predicting both very low and really high values. I'll therefore try to delete the values that have the highest leverage on the model and see if it results in an increase of prediction quality:

```{r modell optimisation}

tr_mr = tr_mr[-c(13081,88785,69663),]
lm_log_dep_corr <- lm_log <- lm(data = tr_mr, log(rent_full) ~ .)
summary(lm_log_dep_corr)
plot(lm_log_dep_corr)
```

Indeed, our model fit increased by 1%.

The next step is a prediction based on a 80% / 20% split. I'll use a logged dependent value, and kick out some of the categorical values. The reson for this being that we don't have the same factor distribution in test- and trainingset. This creates a problem, bacause we do not have the same cantons / floors as regressors and thus can't predict the outcome.

We could surpass this by using dummy variables, but when I tried it, I only got non-significant values.

```{r prediction_lm 1}
split_size <- .8
sample_size <- floor(split_size * nrow(tr_mr))
set.seed(123)
train_ind <- sample(seq_len(nrow(tr_mr)), size = sample_size)

training <- tr_mr[train_ind,]
test <- tr_mr[-train_ind,]

trn <-  select(training, -c(KTKZ, floors))
tst <- select(test, -c(KTKZ,floors))

lm_fit <- lm(data = trn, formula = log(rent_full) ~ .)
summary(lm_fit)

tst$predict <- stats::predict(lm_fit, tst)


tst %>% mutate(predictors = exp(predict)) -> tst
na.omit(tst) -> tst

RMSE(tst$predictors, tst$rent_full)


tst <- tst[-7863,] #deleting outlier

ggplot(tst, aes(rent_full, predictors)) +
  geom_point()


```

We significantly lost prediction power, but it can be used as an approximate regression model.

But I want to further improve on the model. That's why I am going to take another approach, and fit a Lasso / Ridge-Regression on the Dataset that contains *both* Micro Ratings and our standard regressors.

Let's see where we land.

I need to convert the dataset first, because the caret-package I am going to use does not work with factors and logical values.

I'll then only choose values with a significant effect on the rent.


```{r preparation for lasso, include=FALSE}

training_reduced_large %>% select(!c(GDENR)) -> baseset
summary(baseset)

#Create a model that is computable by the new mode. It only works with integers
baseset <- baseset %>% mutate_if(is.factor, as.integer) %>% mutate_if(is.logical, as.integer)
summary(baseset)

summary(lm(data = baseset, formula = log(rent_full) ~.))

#choosing significant variables with only a small ampint of NA

base_impute <- baseset %>% select(rent_full,
                                  KTKZ,
                                  area,
                                  msregion,
                                  cabletv,
                                  elevator,
                                  balcony,
                                  parking_indoor,
                                  parking_outside,
                                  quarter_general,
                                  rooms,
                                  Micro_rating,
                                  Micro_rating_NoiseAndEmission,
                                  Micro_rating_Accessibility,
                                  Micro_rating_DistrictAndArea,
                                  Micro_rating_SunAndView,
                                  Noise_max,
                                  apoth_pix_count_km2,
                                  avg_anzhl_geschosse,
                                  dist_to_4G,
                                  dist_to_school_1,
                                  dist_to_haltst,
                                  dist_to_train_stat,
                                  geb_wohnnutz_total,
                                  dist_to_river,
                                  restaur_pix_count_km2,
                                  superm_pix_count_km2)



library(mice)
#we first impute the missing values based on a multivariate imputation
test_impute <- mice(base_impute, m = 1, seed = 123)

complete_set <- complete(test_impute,1)

summary(lm(data = baseset, formula = rent_full ~.))

summary(lm(data = complete_set, formula = rent_full ~.))


summary(complete_set)

#What we see is that an imputation works well for the aggreagte level - the coefficients (median, mean & quantile) stay the same, but the really loose
#interpretability on a row by row-level.

```
Result: the overall fit of the model got worse!


Try 2, now with lasso and ridge-comparison.

```{r Lasso Ridge and linear model, echo=FALSE}
set.seed(4900)

#Create a model that is computable by the new mode. It only works with integers
base_lasso <- complete_set %>% mutate_if(is.factor, as.integer) %>% mutate_if(is.logical, as.integer)


#Splitting up X and Y variables

X <- base_lasso



#Normalizing data
#processed <- preProcess(X, method = c("center", "scale"))
#X <- predict(processed, X)


index <- createDataPartition(X$rent_full, p=0.75, list=FALSE)

X_train <- X[index,2:27]
X_test <- X[-index,2:27 ]
Y_train <- X[index,1]
Y_test<-X[-index,1]

lasso_train <- caret::train(x = X_train, 
                      y = Y_train,
                      method = "glmnet", 
                      tuneGrid = expand.grid(alpha = 1, lambda = 1))

ridge_train <- caret::train(x = X_train, 
                      y = Y_train,
                      method = "glmnet", 
                      tuneGrid = expand.grid(alpha = 0, lambda = 1))

linear_train <- caret::train(x = X_train, 
                      y = Y_train,
                      method = "lm")

#create predictions
predictions_lasso <- lasso_train %>% predict(X_test)
predictions_ridge <- ridge_train %>% predict(X_test)
predictions_linear <- linear_train %>% predict(X_test)


#get R2 score of predictions
data.frame( Ridge_R2 = R2(predictions_ridge, Y_test),
            Lasso_R2 = R2(predictions_lasso, Y_test),
            Linear_R2 = R2(predictions_linear, Y_test))

#get MSE of predictions
data.frame( Ridge_RMSE = RMSE(predictions_ridge, Y_test) , 
  Lasso_RMSE = RMSE(predictions_lasso, Y_test),
  Linear_RMSE = RMSE(predictions_linear, Y_test))

#Optimising the lambda regularization parameter by choosing the best R2 value

parameters <- c(seq(0.1, 2, by =0.1) ,  seq(2, 5, 0.5) , seq(5, 25, 1))

lasso_opt<-train(y = Y_train,
                 x = X_train,
                 method = 'glmnet', 
                 tuneGrid = expand.grid(alpha = 1, lambda = parameters) ,
                 metric =  "Rsquared"
               ) 

ridge_opt<-train(y = Y_train,
                 x = X_train,
                 method = 'glmnet', 
                 tuneGrid = expand.grid(alpha = 0, lambda = parameters),
                 metric =  "Rsquared"
               ) 
linear_opt<-train(y = Y_train, 
              x = X_train, 
              method = 'lm',
              metric =  "Rsquared"
              )

print(paste0('Lasso best parameters: ' , lasso_opt$finalModel$lambdaOpt))
print(paste0('Ridge best parameters: ' , ridge_opt$finalModel$lambdaOpt))

predictions_lasso_opt <- lasso_opt %>% predict(X_test)
predictions_ridge_opt <- ridge_opt %>% predict(X_test)
predictions_linear_opt <- linear_opt %>% predict(X_test)

data.frame(
  Ridge_R2 = R2(predictions_lasso_opt, Y_test),
  Lasso_R2 = R2(predictions_lasso_opt, Y_test),
  Linear_R2 = R2(predictions_linear_opt, Y_test)
)

print("Optimized coefficients:")
data.frame(
  ridge = as.data.frame.matrix(coef(ridge_opt$finalModel, ridge_opt$finalModel$lambdaOpt)),
  lasso = as.data.frame.matrix(coef(lasso_opt$finalModel, lasso_opt$finalModel$lambdaOpt)), 
  linear = (linear_opt$finalModel$coefficients)
) %>%   rename(lasso = X1, ridge = X1.1)


```

All of our models have similar results. Lets check the predictions vs. the actual values in a scatterplot:

```{r Comparison plot models, echo=FALSE}
lasso_scatter <- as_tibble(as_vector(predictions_lasso_opt))

lasso_scatter$true <- Y_test

ggplot(lasso_scatter, aes(true,value)) +
  geom_point() +
  labs(title = "Optimized Lasso model",
       subtitle = "True values vs. predictions",
       xlab = "Actual values",
       ylab = "Predictions")

plot(lasso_opt)

ridge_scatter <- as_tibble(as_vector(predictions_ridge_opt))

ridge_scatter$true <- Y_test

ggplot(ridge_scatter, aes(true,value)) +
  geom_point() +
    labs(title = "Optimized Ridge model",
       subtitle = "True values vs. predictions",
       xlab = "Actual values",
       ylab = "Predictions")

plot(ridge_opt)

linear_scatter <- as_tibble(as_vector(predictions_linear_opt))

linear_scatter$true <- Y_test

ggplot(linear_scatter, aes(true,value)) +
  geom_point() +
   labs(title = "Standard Linear model",
       subtitle = "True values vs. predictions",
       xlab = "Actual values",
       ylab = "Predictions")

```

That's not really a good result. Let's look how far off we are:

```{r Prediction offset, echo=FALSE}
print("Amount of predictions that were off by 400.- CHF")
nrow(lasso_scatter[c(which((lasso_scatter$true - lasso_scatter$value) > 400 | (lasso_scatter$value- lasso_scatter$true) > 400 )),])

```


Here we have a List of all the values that were off by a margin of 400.- CHF (aproximately the RMSE) - that's nearly 1/4 of the testset. We really need a better model.


```{r Lasso Ridge and linear model, echo=FALSE}

training_reduced_large %>% 
  mutate(home_type = as.factor(home_type)) -> training_reduced_large

training_reduced_large %>% 
  mutate(home_type = as.factor(home_type)) %>% 
  mutate(across(c("area",
                  "Avg_size_household", 
                  "dist_to_haltst",
                  "dist_to_highway",
                  "dist_to_lake",
                  "dist_to_main_stat",
                  "dist_to_river",
                  "dist_to_school_1",
                  "dist_to_train_stat"), 
                log)) -> training_logged

training_logged %>% select(!c(GDENR)) -> base_log_imp
summary(base_log_imp)

#Create a model that is computable by the new mode. It only works with integers
summary(baseset)

summary(lm(data = training_reduced_large, formula = log(rent_full) ~.))

#choosing significant variables with only a small ampint of NA

base_imputed_log <- base_log_imp %>% select(rent_full,
                                  KTKZ,
                                  area,
                                  msregion,
                                  cabletv,
                                  elevator,
                                  balcony,
                                  parking_indoor,
                                  parking_outside,
                                  quarter_general,
                                  rooms,
                                  Micro_rating,
                                  Micro_rating_NoiseAndEmission,
                                  Micro_rating_Accessibility,
                                  Micro_rating_DistrictAndArea,
                                  Micro_rating_SunAndView,
                                  Noise_max,
                                  apoth_pix_count_km2,
                                  avg_anzhl_geschosse,
                                  dist_to_4G,
                                  dist_to_school_1,
                                  dist_to_haltst,
                                  dist_to_train_stat,
                                  geb_wohnnutz_total,
                                  dist_to_river,
                                  restaur_pix_count_km2,
                                  superm_pix_count_km2)



library(mice)
#we first impute the missing values based on a multivariate imputation
test_impute_log <- mice(base_log_imp, m = 1, seed = 4900)

complete_set_log <- complete(test_impute_log,1)

summary(lm(data = base_imputed_log, formula = rent_full ~.))

summary(lm(data = complete_set_log, formula = log(rent_full) ~.))


summary(complete_set)

X <- base_imputed_log



#Normalizing data
#processed <- preProcess(X, method = c("center", "scale"))
#X <- predict(processed, X)


index <- createDataPartition(training_reduced_large$rent_full, p=0.75, list=FALSE)

X_train <- X[index,1:27]
X_test <- X[-index,2:27 ]
Y_train <- X[index,1]
Y_test<-X[-index,1]

lm_testing <- lm(data = X_train, formula = log(rent_full) ~.)

pred <- predict(lm_testing,X_test)
df <- data.frame(exp(pred), Y_test$rent_full)
df <- na.omit(df)
RMSE(df$exp.pred., df$Y_test.rent_full)

lasso_train <- caret::train(x = X_train, 
                            y = Y_train$rent_full,
                            method = "glmnet", 
                            tuneGrid = expand.grid(alpha = 1, lambda = 1))

ridge_train <- caret::train(x = X_train, 
                      y = Y_train,
                      method = "glmnet", 
                      tuneGrid = expand.grid(alpha = 0, lambda = 1))

linear_train <- caret::train(x = X_train, 
                      y = Y_train,
                      method = "lm")

#create predictions
predictions_lasso <- lasso_train %>% predict(X_test)
predictions_ridge <- ridge_train %>% predict(X_test)
predictions_linear <- linear_train %>% predict(X_test)


#get R2 score of predictions
data.frame( Ridge_R2 = R2(predictions_ridge, Y_test),
            Lasso_R2 = R2(predictions_lasso, Y_test),
            Linear_R2 = R2(predictions_linear, Y_test))

#get MSE of predictions
data.frame( Ridge_RMSE = RMSE(predictions_ridge, Y_test) , 
  Lasso_RMSE = RMSE(predictions_lasso, Y_test),
  Linear_RMSE = RMSE(predictions_linear, Y_test))

#Optimising the lambda regularization parameter by choosing the best R2 value

parameters <- c(seq(0.1, 2, by =0.1) ,  seq(2, 5, 0.5) , seq(5, 25, 1))

lasso_opt<-train(y = Y_train$rent_full,
                 x = X_train,
                 method = 'glmnet', 
                 tuneGrid = expand.grid(alpha = 1, lambda = parameters) ,
                 metric =  "Rsquared"
               ) 

ridge_opt<-train(y = Y_train,
                 x = X_train,
                 method = 'glmnet', 
                 tuneGrid = expand.grid(alpha = 0, lambda = parameters),
                 metric =  "Rsquared"
               ) 
linear_opt<-train(y = Y_train, 
              x = X_train, 
              method = 'lm',
              metric =  "Rsquared"
              )

print(paste0('Lasso best parameters: ' , lasso_opt$finalModel$lambdaOpt))
print(paste0('Ridge best parameters: ' , ridge_opt$finalModel$lambdaOpt))

predictions_lasso_opt <- lasso_opt %>% predict(X_test)
predictions_ridge_opt <- ridge_opt %>% predict(X_test)
predictions_linear_opt <- linear_opt %>% predict(X_test)

data.frame(
  Ridge_R2 = R2(predictions_lasso_opt, Y_test),
  Lasso_R2 = R2(predictions_lasso_opt, Y_test),
  Linear_R2 = R2(predictions_linear_opt, Y_test)
)

print("Optimized coefficients:")
data.frame(
  ridge = as.data.frame.matrix(coef(ridge_opt$finalModel, ridge_opt$finalModel$lambdaOpt)),
  lasso = as.data.frame.matrix(coef(lasso_opt$finalModel, lasso_opt$finalModel$lambdaOpt)), 
  linear = (linear_opt$finalModel$coefficients)
) %>%   rename(lasso = X1, ridge = X1.1)


```



